{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFRecordExtractor:\n",
    "    def __init__(self, tfrecord_file):\n",
    "        self.tfrecord_file = tfrecord_file\n",
    "        self.count = 0\n",
    "\n",
    "    def _extract_fn(self,tfrecord):\n",
    "\n",
    "        # Extract features using the keys set during creation\n",
    "        feature = {'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "                   'label_normal': tf.io.FixedLenFeature([], tf.int64),\n",
    "                   'image': tf.io.FixedLenFeature([], tf.string)}\n",
    "\n",
    "\n",
    "        # Decode the record read by the reader\n",
    "        features = tf.io.parse_single_example(tfrecord, features=feature)\n",
    "        \n",
    "        # Convert the image data from string back to the numbers\n",
    "        image = tf.io.decode_raw(features['image'], tf.uint8)\n",
    "        #image = tf.image.decode_png(features['image'],channels=1)\n",
    "\n",
    "        label = features['label']\n",
    "\n",
    "        label_normal = features['label_normal']\n",
    "\n",
    "        image = tf.reshape(image, [299, 299, 1])\n",
    "\n",
    "        return [image,label,label_normal]\n",
    "\n",
    "\n",
    "    def post_process_images(self):\n",
    "        image_data_list = self.get_images()\n",
    "        \n",
    "        b_c_df = pd.DataFrame(columns=['id', 'class', 'normal_class'])\n",
    "\n",
    "        #id_list = []\n",
    "        class_list = []\n",
    "        #normal_class_list = []\n",
    "        image_list=[]\n",
    "        print(len(image_data_list))\n",
    "        images_stacked=np.empty((299,299,700))\n",
    "        print(\"Begin extracting in post processing\")\n",
    "        for image_data in image_data_list:\n",
    "            image_list.append(image_data[0])\n",
    "            class_list.append(image_data[1])\n",
    "        print(\"Done extracting in post processing\")\n",
    "        print(\"Starting to stack\")\n",
    "        iter_num=len(image_list)//700\n",
    "        residual=len(image_list)%700\n",
    "        string_file=self.tfrecord_file\n",
    "        for i in range(iter_num+1):\n",
    "            count=0\n",
    "            if i<iter_num:\n",
    "                inner_range=range(700*i,(i+1)*700,1)\n",
    "            else:\n",
    "                inner_range=range(i*700,i*700+residual,1)\n",
    "            for j in inner_range:\n",
    "                images_stacked[:,:,count]=image_list[j].numpy().reshape([299,299])\n",
    "                count=count+1\n",
    "            print(count)\n",
    "            np.savez_compressed(string_file[:string_file.index('.')]+'_'+str(i)+'_'+'count: '+str(count)+'.npz',images_stacked[:,:,0:count])\n",
    "        \n",
    "        #id_arr = np.array(id_list)\n",
    "        #f2=gzip.GzipFile(string_file[:string_file.index('.')]+'_'+'id_arr.npy.gz',\"w\")\n",
    "        #np.save(f2,id_arr)\n",
    "        #f2.close()\n",
    "        \n",
    "        class_arr = np.array(class_list)\n",
    "        np.savez_compressed(string_file[:string_file.index('.')]+'_'+'class_arr.npz',class_arr)\n",
    "        \n",
    "        #normal_class_arr = np.array(normal_class_list)\n",
    "        #plt.imshow(img)\n",
    "        \n",
    "    def get_images(self):\n",
    "        # Initialize all tfrecord paths\n",
    "    \n",
    "        dataset = tf.data.TFRecordDataset([self.tfrecord_file])\n",
    "        dataset = dataset.map(self._extract_fn)\n",
    "        image_data_list=[]\n",
    "        for image_features in dataset:\n",
    "            image_raw=image_features\n",
    "            image_data_list.append(image_raw)\n",
    "        return image_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11177\n",
      "Begin extracting in post processing\n",
      "Done extracting in post processing\n",
      "Starting to stack\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "677\n"
     ]
    }
   ],
   "source": [
    "t = TFRecordExtractor('training10_3.tfrecords') \n",
    "t.post_process_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11177\n",
      "Begin extracting in post processing\n",
      "Done extracting in post processing\n",
      "Starting to stack\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "677\n"
     ]
    }
   ],
   "source": [
    "t = TFRecordExtractor('training10_2.tfrecords') \n",
    "t.post_process_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11177\n",
      "Begin extracting in post processing\n",
      "Done extracting in post processing\n",
      "Starting to stack\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "677\n"
     ]
    }
   ],
   "source": [
    "t = TFRecordExtractor('training10_1.tfrecords') \n",
    "t.post_process_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11177\n",
      "Begin extracting in post processing\n",
      "Done extracting in post processing\n",
      "Starting to stack\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "700\n",
      "677\n"
     ]
    }
   ],
   "source": [
    "t = TFRecordExtractor('training10_0.tfrecords') \n",
    "t.post_process_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
